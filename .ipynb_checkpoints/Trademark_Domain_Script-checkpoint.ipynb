{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import pythonwhois\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_stub = 'farm'\n",
    "domain_list = ['.com', '.org', '.net', '.io', '.co', '.iq', '.it', '.boss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contains_letters = ''\n",
    "no_letters = '4'\n",
    "url = 'http://itools.subhashbose.com/wordfind/containing/'+contains_letters+'/no-of-letters_equal-to_'+no_letters\n",
    "try:\n",
    "    content = urllib2.urlopen(url).read()\n",
    "except urllib2.URLError, e:\n",
    "        print('SoupError', e)\n",
    "soup = BeautifulSoup(content)\n",
    "\n",
    "results = soup.find(id='result')\n",
    "word_list = [text for text in results.stripped_strings]\n",
    "\n",
    "# Delete first entry in list\n",
    "word_list.pop(0)\n",
    "\n",
    "# Add additional words\n",
    "word_list.insert(0, u'robot')\n",
    "word_list.insert(0, u'kind')\n",
    "\n",
    "# Add name_stub\n",
    "word_list = [name_stub+word for word in word_list]\n",
    "\n",
    "# Add other names\n",
    "#german_words = ['datageist', 'datagarden', 'delicadata', 'datastrudel', 'databahn', 'datakraut', 'datawunder', 'dataphil', 'datahunt', 'databeat', 'dataoo']\n",
    "#word_list = word_list + german_words\n",
    "#word_list = ['datalook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US-Trademark</th>\n",
       "      <th>.com</th>\n",
       "      <th>.org</th>\n",
       "      <th>.net</th>\n",
       "      <th>.de</th>\n",
       "      <th>.co</th>\n",
       "      <th>.io</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Google</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATALOOK</th>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> DATALOOK is a site for sharing data-driven pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         US-Trademark .com .org .net  .de  .co  .io Twitter Google  \\\n",
       "DATALOOK          NaN  NaN  NaN  NaN  NaN  NaN  NaN     NaN    NaN   \n",
       "\n",
       "                                                    Example  \n",
       "DATALOOK  DATALOOK is a site for sharing data-driven pro...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(index = [x.upper() for x in word_list], columns= ['US-Trademark', '.com', '.org', '.net', '.de', '.co', '.io', 'Twitter', 'Google'])\n",
    "\n",
    "# Add sentence to get a feeling for the name\n",
    "df['Example'] = df.index + ' is a site for sharing data-driven projects for social good.'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATALOOK\n",
      ".com\n",
      ".org\n",
      ".net\n",
      ".de\n",
      ".co\n",
      ".io\n",
      "395000\n"
     ]
    }
   ],
   "source": [
    "#https://api.twitter.com/1.1/users/lookup.json?screen_name='+name\n",
    "#word_list2 = word_list[75:]\n",
    "for word in word_list:\n",
    "    \n",
    "    print word.upper()\n",
    "    # Twitter\n",
    "    twitter_url = 'https://twitter.com/users/username_available?username='+word\n",
    "    try:\n",
    "        twitter = json.loads(urllib2.urlopen(twitter_url).read())\n",
    "        if twitter['reason'] == 'available':\n",
    "            df['Twitter'][word.upper()] = 'X'\n",
    "        else:\n",
    "            df['Twitter'][word.upper()] = ''\n",
    "        \n",
    "    except urllib2.URLError, e:\n",
    "        print('TwitterError', e)\n",
    "        \n",
    "    # US-Trademark\n",
    "    tm_url = 'http://www.markerapi.com/api/v1/trademark/search/'+word+'/username/dataforgood/password/Cmk6P2ZQXN'\n",
    "    try:\n",
    "        trademark = json.loads(urllib2.urlopen(tm_url).read())\n",
    "        \n",
    "        if trademark['count'] == 0:\n",
    "            df['US-Trademark'][word.upper()] = 'X'\n",
    "        else:\n",
    "            df['US-Trademark'][word.upper()] = str(trademark['count'])\n",
    "            \n",
    "    except urllib2.URLError, e:\n",
    "        print('TrademarkError', e)\n",
    "        \n",
    "    # Domains    \n",
    "    for tld in domain_list:\n",
    "        try:\n",
    "            domain_check = pythonwhois.get_whois(word+tld)\n",
    "        except Exception, e:\n",
    "            import traceback\n",
    "            print traceback.format_exc()\n",
    "            pass\n",
    "        print tld\n",
    "        #print domain_check['contacts']['admin']\n",
    "        \n",
    "        if domain_check['contacts']['admin'] == None:\n",
    "            df[tld][word.upper()] = 'X'\n",
    "        else: \n",
    "            df[tld][word.upper()] = ''\n",
    "        # Time delay necessary for whois server - otherwise blocked\n",
    "        sleep(5)\n",
    "        \n",
    "    # Google results\n",
    "    url = 'http://www.google.com/search?hl=en&q='+word\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        req = urllib2.Request(url,headers=hdr)\n",
    "        content = urllib2.urlopen(req).read()\n",
    "    except urllib2.URLError, e:\n",
    "        print('SoupError', e)\n",
    "\n",
    "    soup = BeautifulSoup(content)\n",
    "    #no_results = re.findall(r'About (.+?) results', soup.get_text())\n",
    "    no_results = str(soup.find(id='resultStats').get_text()).replace(',','')\n",
    "    df['Google'][word.upper()] = int(re.findall(r'\\d+', no_results)[0])\n",
    "    print re.findall(r'\\d+', no_results)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US-Trademark</th>\n",
       "      <th>.com</th>\n",
       "      <th>.org</th>\n",
       "      <th>.net</th>\n",
       "      <th>.de</th>\n",
       "      <th>.co</th>\n",
       "      <th>.io</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Google</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATALOOK</th>\n",
       "      <td> X</td>\n",
       "      <td> </td>\n",
       "      <td> X</td>\n",
       "      <td> </td>\n",
       "      <td> X</td>\n",
       "      <td> X</td>\n",
       "      <td> X</td>\n",
       "      <td> </td>\n",
       "      <td> 395000</td>\n",
       "      <td> DATALOOK is a site for sharing data-driven pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         US-Trademark .com .org .net .de .co .io Twitter  Google  \\\n",
       "DATALOOK            X         X        X   X   X          395000   \n",
       "\n",
       "                                                    Example  \n",
       "DATALOOK  DATALOOK is a site for sharing data-driven pro...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#writer = pd.ExcelWriter('Trademark_Domain_Script_company_names.xlsx')\n",
    "#df.to_excel(writer)\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://register.dpma.de/DPMAregister/marke/einsteiger\n",
    "- http://www.wipo.int/romarin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- or with https://jsonwhois.com/pricing (max. 500 calls/month)\n",
    "- http://freedomainapi.com/?key=wpxcfqma4x&domain='+word+tld"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
